\section{Model description}
\label{sec:model}

Model selection and feature designing were vastly influenced by the radical difference in the quality of two given datasets. As we mentioned, the larger publisher-based dataset had a large number of mislabelled articles. For example, an article about diet tips or some other non-political news were often labelled as hyperpartisan news, solely on a fact that the publisher is classified as a generally biased news source. This mislabelling often caused our models to wrongly guess on what really indicates hyperpartisan in news articles. Since the larger dataset often gave us relatively low accuracy, we decided to try a different approach. 

Our first submitted model was trained only on the smaller and more accurate dataset. We decided to use SVC with GridSearch to maximize our accuracy on such a small dataset. Our best accuracy on the validation set, after cross-validation and with all features in place, was 77.9\%. Furthermore, for our second submitted model, we have decided to use a self-learning method to acquire more quality data from the larger dataset. Our first step was to train a logistic regression model on half of the smaller dataset and once trained, we tested that model on the larger dataset.All correctly guessed articles were collected to a new dataset. Once we extracted and combined all quality articles, we again used SVC model. Our final accuracy on this model was also 77\%.